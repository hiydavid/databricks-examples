{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27c35706",
   "metadata": {},
   "source": [
    "# Driver Notebook\n",
    "\n",
    "For more information, check out how to [author and deploy an MCP tool-calling OpenAI Responses API agent](https://docs.databricks.com/aws/en/notebooks/source/generative-ai/openai-mcp-tool-calling-agent.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358bc5ad",
   "metadata": {},
   "source": [
    "## Setup\n",
    "This repo is designed to run in a local IDE with Databricks Connect enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8654781",
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks.connect import DatabricksSession\n",
    "\n",
    "spark = DatabricksSession.builder.remote(serverless=True).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64961af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "\n",
    "# TODO make sure you update the config file before this\n",
    "\n",
    "configs = mlflow.models.ModelConfig(development_config=\"./config.yaml\")\n",
    "databricks_config = configs.get(\"databricks\")\n",
    "agent_config = configs.get(\"agent\")\n",
    "\n",
    "CATALOG = databricks_config[\"catalog\"]\n",
    "SCHEMA = databricks_config[\"schema\"]\n",
    "UC_MODEL = databricks_config[\"model\"]\n",
    "WORKSPACE_URL = databricks_config[\"workspace_url\"]\n",
    "SQL_WAREHOUSE_ID = databricks_config[\"sql_warehouse_id\"]\n",
    "UC_TABLES = agent_config[\"tools\"][\"tables\"]\n",
    "UC_FUNCTIONS = [\n",
    "    uc_func[\"function_name\"] for uc_func in agent_config[\"tools\"][\"uc_functions\"]\n",
    "]\n",
    "UC_CONNECTION = agent_config[\"tools\"][\"uc_connection\"]\n",
    "LLM_ENDPOINT_NAME = agent_config[\"llm\"][\"endpoint_name\"]\n",
    "VECTOR_SEARCH_INDEX = agent_config[\"tools\"][\"vector_search\"][\"index_name\"]\n",
    "GENIE_SPACE_ID = agent_config[\"tools\"][\"genie\"][\"space_id\"]\n",
    "MLFLOW_EXPERIMENT_ID = databricks_config[\"mlflow_experiment_id\"]\n",
    "AGENT_NAME = agent_config[\"name\"]\n",
    "\n",
    "SECRET_SCOPE_NAME = databricks_config.get(\"databricks_pat\").get(\"secret_scope_name\")\n",
    "SECRET_KEY_NAME = databricks_config.get(\"databricks_pat\").get(\"secret_key_name\")\n",
    "\n",
    "# Set up authentication for Databricks services\n",
    "databricks_token = dbutils.secrets.get(scope=SECRET_SCOPE_NAME, key=SECRET_KEY_NAME)\n",
    "\n",
    "os.environ[\"DB_MODEL_SERVING_HOST_URL\"] = WORKSPACE_URL\n",
    "os.environ[\"DATABRICKS_GENIE_PAT\"] = databricks_token\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = databricks_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f8bcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "\n",
    "try:\n",
    "    experiment = mlflow.get_experiment(experiment_id=MLFLOW_EXPERIMENT_ID)\n",
    "    mlflow.set_experiment(experiment_id=MLFLOW_EXPERIMENT_ID)\n",
    "    print(f\"Set to existing experiment: {MLFLOW_EXPERIMENT_ID}\")\n",
    "except mlflow.exceptions.RestException as e:\n",
    "    if \"does not exist\" in str(e):\n",
    "        print(f\"Experiment not found. Must create one first.\")\n",
    "    else:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777027af",
   "metadata": {},
   "source": [
    "## Load & test agent\n",
    "\n",
    "Make sure you go to the MLflow experiment to look at trace data as you develop & debug the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03488d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d18db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_questions = [\n",
    "    # \"Compare and contrast the annual net income growth in the past 10 years between AAPL and AXP\",\n",
    "    # \"What risks face APPL in 2022 and 2023?\",\n",
    "    \"What was Apple's stock price on 10/2/2025?\"\n",
    "]\n",
    "\n",
    "input_example = {\n",
    "    \"input\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": sample_questions[0],\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa582f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = AGENT.predict(input_example)\n",
    "print(result.model_dump(exclude_none=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7c61c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in AGENT.predict_stream(input_example):\n",
    "    print(event, \"-----------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eece6839",
   "metadata": {},
   "source": [
    "## Log the agent as an MLflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db63873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models.resources import (\n",
    "    DatabricksUCConnection,\n",
    "    DatabricksFunction,\n",
    "    DatabricksGenieSpace,\n",
    "    DatabricksSQLWarehouse,\n",
    "    DatabricksServingEndpoint,\n",
    "    DatabricksTable,\n",
    "    DatabricksVectorSearchIndex,\n",
    ")\n",
    "\n",
    "# TODO: Define your resources here\n",
    "resources = [\n",
    "    DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME),\n",
    "    DatabricksGenieSpace(genie_space_id=GENIE_SPACE_ID),\n",
    "    DatabricksSQLWarehouse(warehouse_id=SQL_WAREHOUSE_ID),\n",
    "    DatabricksVectorSearchIndex(index_name=VECTOR_SEARCH_INDEX),\n",
    "    DatabricksUCConnection(connection_name=UC_CONNECTION),\n",
    "]\n",
    "for function_name in UC_FUNCTIONS:\n",
    "    resources.append(DatabricksFunction(function_name=function_name))\n",
    "for table_name in UC_TABLES:\n",
    "    resources.append(DatabricksTable(table_name=table_name))\n",
    "\n",
    "print(resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11bcbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        name=\"agent\",\n",
    "        python_model=os.path.join(os.getcwd(), \"agent.py\"),\n",
    "        model_config=os.path.join(os.getcwd(), \"config.yaml\"),\n",
    "        input_example=input_example,\n",
    "        resources=resources,\n",
    "        pip_requirements=[\"-r ../requirements.txt\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d64298f",
   "metadata": {},
   "source": [
    "## Evaluate the agent with MLflow 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4182751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "evals_json_path = \"./evals/eval-questions.json\"\n",
    "\n",
    "with open(evals_json_path, \"r\") as f:\n",
    "    eval_dataset_list = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dceafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.genai.scorers import (\n",
    "    Correctness,\n",
    "    RelevanceToQuery,\n",
    "    RetrievalGroundedness,\n",
    "    RetrievalRelevance,\n",
    "    Safety,\n",
    ")\n",
    "\n",
    "# To avoid concurrency issue\n",
    "# os.environ[\"MLFLOW_GENAI_EVAL_MAX_WORKERS\"] = \"1\"\n",
    "\n",
    "eval_results = mlflow.genai.evaluate(\n",
    "    data=eval_dataset_list,\n",
    "    predict_fn=lambda input: AGENT.predict({\"input\": input}),\n",
    "    scorers=[\n",
    "        Correctness(),\n",
    "        RelevanceToQuery(),\n",
    "        Safety(),\n",
    "        RetrievalGroundedness(),\n",
    "        RetrievalRelevance(),\n",
    "    ],  # add more scorers here if they're applicable\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9701de",
   "metadata": {},
   "source": [
    "## Run pre-deployment agent validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89d1a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.models.predict(\n",
    "    model_uri=f\"runs:/{logged_agent_info.run_id}/agent\",\n",
    "    input_data={\"input\": [{\"role\": \"user\", \"content\": \"Hello!\"}]},\n",
    "    env_manager=\"uv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbb6a82",
   "metadata": {},
   "source": [
    "## Register the model to Unity Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71750e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_UC_MODEL_NAME = f\"{CATALOG}.{SCHEMA}.{UC_MODEL}\"\n",
    "\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=logged_agent_info.model_uri,\n",
    "    name=FULL_UC_MODEL_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8756d52b",
   "metadata": {},
   "source": [
    "## Deploy the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4d1de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "\n",
    "agents.deploy(\n",
    "    FULL_UC_MODEL_NAME,\n",
    "    uc_registered_model_info.version,\n",
    "    tags={\"endpointSource\": \"docs\"},\n",
    "    environment_vars={\n",
    "        \"DATABRICKS_GENIE_PAT\": f\"{{{{secrets/{SECRET_SCOPE_NAME}/{SECRET_KEY_NAME}}}}}\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6346fb",
   "metadata": {},
   "source": [
    "## Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55f9035",
   "metadata": {},
   "source": [
    "* Test the agent endpoint via Playground or the Review App\n",
    "* Contine to iterate on the agent\n",
    "* Use the full Agent Evaluation Suite on MLflow 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
